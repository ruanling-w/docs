# Create chat autocomplete in deepseek v3.1 (streaming).

## OpenAPI Specification

```yaml
openapi: 3.0.1
info:
  title: ""
  description: ""
  version: 1.0.0
paths:
  /v1/chat/completions:
    post:
      summary: Create chat autocomplete in deepseek v3.1 (streaming).
      deprecated: false
      description: ""
      tags:
        - Chat/ChatGpt Interface/ChatGPT Chat
      parameters:
        - name: Content-Type
          in: header
          description: ""
          required: true
          example: application/json
          schema:
            type: string
        - name: Accept
          in: header
          description: ""
          required: true
          example: application/json
          schema:
            type: string
        - name: Authorization
          in: header
          description: ""
          required: false
          example: Bearer {{YOUR_API_KEY}}
          schema:
            type: string
        - name: X-Forwarded-Host
          in: header
          description: ""
          required: false
          example: localhost:5173
          schema:
            type: string
      requestBody:
        content:
          application/json:
            schema:
              type: object
              properties:
                model:
                  type: string
                  description: The ID of the model used.
                max_tokens:
                  type: integer
                  description: >-
                    Limit the maximum number of completion tokens generated by the model in a single request. The total length of the input and output tokens is limited by the model's context length.
                messages:
                  type: array
                  items:
                    type: object
                    properties:
                      role:
                        type: string
                      content:
                        type: string
                    required:
                      - role
                      - content
                    x-apifox-orders:
                      - role
                      - content
                  description: The message list of the conversation.
                temperature:
                  type: integer
                  description: >-
                    The sampling temperature to use is between 0 and 2. Higher values ​​(such as 0.8) will make the output more random, while lower values ​​(such as 0.2) will make the output more focused and deterministic.
                stream:
                  type: boolean
                  description: >-
                    If set to True, messages will be sent incrementally in the form of SSE (server-sent events). The message stream ends with
                    data: [DONE].
                stream_options:
                  type: object
                  properties:
                    include_usage:
                      type: boolean
                      description: >-
                        If set to true, an additional chunk will be transmitted before the final `data: [DONE]` section of the streaming message. The `usage` field on this chunk displays token usage statistics for the entire request, while the `choices` field will always be an empty array. All other chunks will also contain a `usage` field, but its value will be null.
                  x-apifox-orders:
                    - include_usage
                  description: Streaming output related options. This parameter can only be set when the stream parameter is true.
                thinking:
                  type: object
                  properties:
                    type:
                      type: string
                      description: |-
                        enabled: Enabled by default; forces deep reasoning to be turned on.
                        disabled: Forces deep reasoning to be turned off.
                        auto: The model automatically decides whether to use deep reasoning.
                  x-apifox-orders:
                    - type
                  description: Some models of deep thinking ability support controlling whether to turn deep thinking ability off via the thinking field.
              required:
                - model
                - messages
              x-apifox-orders:
                - model
                - max_tokens
                - messages
                - temperature
                - stream
                - stream_options
                - thinking
            example:
              model: deepseek-v3-1-250821
              max_tokens: 1000
              messages:
                - role: system
                  content: You are a helpful assistant.
                - role: user
                  content: Hello
              temperature: 1
              stream: true
              stream_options:
                include_usage: true
              thinking:
                type: enabled
      responses:
        "200":
          description: ""
          content:
            application/json:
              schema:
                type: object
                properties:
                  id:
                    type: string
                  object:
                    type: string
                  created:
                    type: integer
                  choices:
                    type: array
                    items:
                      type: object
                      properties:
                        index:
                          type: integer
                        message:
                          type: object
                          properties:
                            role:
                              type: string
                            content:
                              type: string
                          required:
                            - role
                            - content
                          x-apifox-orders:
                            - role
                            - content
                        finish_reason:
                          type: string
                      x-apifox-orders:
                        - index
                        - message
                        - finish_reason
                  usage:
                    type: object
                    properties:
                      prompt_tokens:
                        type: integer
                      completion_tokens:
                        type: integer
                      total_tokens:
                        type: integer
                    required:
                      - prompt_tokens
                      - completion_tokens
                      - total_tokens
                    x-apifox-orders:
                      - prompt_tokens
                      - completion_tokens
                      - total_tokens
                required:
                  - id
                  - object
                  - created
                  - choices
                  - usage
                x-apifox-orders:
                  - id
                  - object
                  - created
                  - choices
                  - usage
          headers: {}
          x-apifox-name: OK
      security:
        - bearer: []
      x-apifox-folder: Chat/ChatGpt Interface/ChatGPT Chat
      x-apifox-status: released
      x-run-in-apifox: https://app.apifox.com/web/project/5443236/apis/api-339969197-run
components:
  schemas: {}
  securitySchemes:
    bearer:
      type: http
      scheme: bearer
servers:
  - url: https://api.chainhub.tech
    description: Production Environment
security:
  - bearer: []
```
