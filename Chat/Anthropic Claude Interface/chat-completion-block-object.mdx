---
title: "Chat Completion Chunk Object"
description: "Represents a streamed chunk of a chat completion response."
---

The `chat.completion.chunk` object represents a partial response from a streamed chat completion request.

### Fields

<ResponseField name="id" type="string">
  A unique identifier for the chat completion. Each chunk has the same ID.
</ResponseField>

<ResponseField name="object" type="string">
  The object type, which is always `chat.completion.chunk`.
</ResponseField>

<ResponseField name="created" type="integer">
  A Unix timestamp (in seconds) indicating when the chat completion was created. Each chunk has the same timestamp.
</ResponseField>

<ResponseField name="model" type="string">
  The model used to generate the completion.
</ResponseField>

<ResponseField name="system_fingerprint" type="string">
  This fingerprint represents the backend configuration that the model ran with.
</ResponseField>

<ResponseField name="choices" type="array">
  A list of chat completion choices. Can contain multiple choices if `n` is greater than 1.
  <Expandable title="properties">
    <ResponseField name="index" type="integer">
      The index of the choice in the list of choices.
    </ResponseField>
    <ResponseField name="delta" type="object">
      A chat completion delta object. Sent over a streaming response, containing the contents of the message being built.
      <Expandable title="properties">
        <ResponseField name="role" type="string">
          The role of the author of this message.
        </ResponseField>
        <ResponseField name="content" type="string">
          The contents of the chunk message.
        </ResponseField>
      </Expandable>
    </ResponseField>
    <ResponseField name="finish_reason" type="string">
      The reason the model stopped generating tokens. This will be `stop` if the model hit a natural stop point or a provided stop sequence, `length` if the maximum number of tokens specified in the request was reached, `content_filter` if content was omitted due to a flag from our content filters, `tool_calls` if the model called a tool, or `function_call` (deprecated) if the model called a function.
    </ResponseField>
  </Expandable>
</ResponseField>

### Example

<CodeGroup>
```json Chunk 1
{
  "id": "chatcmpl-123",
  "object": "chat.completion.chunk",
  "created": 1694268190,
  "model": "gpt-3.5-turbo-0613",
  "system_fingerprint": "fp_44709d6fcb",
  "choices": [
    {
      "index": 0,
      "delta": {
        "role": "assistant",
        "content": ""
      },
      "finish_reason": null
    }
  ]
}
```

```json Chunk 2
{
  "id": "chatcmpl-123",
  "object": "chat.completion.chunk",
  "created": 1694268190,
  "model": "gpt-3.5-turbo-0613",
  "system_fingerprint": "fp_44709d6fcb",
  "choices": [
    {
      "index": 0,
      "delta": {
        "content": "Hello"
      },
      "finish_reason": null
    }
  ]
}
```

```json Final Chunk
{
  "id": "chatcmpl-123",
  "object": "chat.completion.chunk",
  "created": 1694268190,
  "model": "gpt-3.5-turbo-0613",
  "system_fingerprint": "fp_44709d6fcb",
  "choices": [
    {
      "index": 0,
      "delta": {},
      "finish_reason": "stop"
    }
  ]
}
```
</CodeGroup>

